{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Object Detection I: Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this session we will train an SSD model using Pascal VOC data. SSD was introduced in the paper:\n",
    "\n",
    "Liu et al. [SSD: Single Shot MultiBox Detector](https://arxiv.org/pdf/1512.02325.pdf). ECCV 2016\n",
    "\n",
    "\n",
    "SSD is an unified framework for object detection with a single network. The original implementation in Caffe can be found [here](https://github.com/weiliu89/caffe/tree/ssd). In this example we will use [an implementation](https://github.com/rykov8/ssd_keras) in keras and tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"../figs/ssd_overview.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from ssd import SSD300\n",
    "from ssd_utils import BBoxUtility, Generator\n",
    "\n",
    "SEED = 4242\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Load the anchor bounding boxes and initialize the bounding box utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 21\n",
    "input_shape = (300, 300, 3)\n",
    "nms_thresh = 0.4\n",
    "priors = pickle.load(open('../data/files/prior_boxes_ssd300.pkl', 'rb'))\n",
    "bbox_util = BBoxUtility(NUM_CLASSES, priors, nms_thresh = nms_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's look at the anchor boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(np.shape(priors))\n",
    "print (priors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "priors[i] = [xmin, ymin, xmax, ymax, varxc, varyc, varw, varh]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create training file based on PASCAL VOC data. This will put all the information (i.e. box coordinates, categories and image paths) into a single file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "pascal_gt = '../data/files/VOC2007.pkl'\n",
    "if not os.path.isfile(pascal_gt):\n",
    "    from PASCAL_VOC.get_data_from_XML import XML_preprocessor\n",
    "    data = XML_preprocessor('../../../../data/VOCdevkit/VOC2007/Annotations/').data\n",
    "    pickle.dump(data,open(pascal_gt,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We load the annotations file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gt = pickle.load(open('../data/files/VOC2007.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's take a peek at this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "key1 = gt.keys()[0]\n",
    "print (key1)\n",
    "print (gt[key1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The first 4 positions are the coordinates of the bounding box, and the remaining ones compose the one-hot vector representing the category. Let's now split the dataset between training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_perc = 0.8\n",
    "keys = sorted(gt.keys())\n",
    "\n",
    "num_train = int(round(train_perc * len(keys)))\n",
    "train_keys = keys[:num_train]\n",
    "val_keys = keys[num_train:]\n",
    "num_val = len(val_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Initialize the generator. Here we must indicate the path where the raw jpeg files are stored and the batch size we want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path_prefix = '../../../../data/VOCdevkit/VOC2007/JPEGImages/'\n",
    "batch_size = 64\n",
    "gen = Generator(gt, bbox_util, batch_size, path_prefix,\n",
    "                train_keys, val_keys,\n",
    "                (input_shape[0], input_shape[1]), do_crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = SSD300(input_shape, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Callbacks in keras are functions that are applied at some points during the training procedure. We will use the one called ```ModelCheckpoint``` which will save the model after every epoch only if it improves validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "mc = ModelCheckpoint('../data/checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                    verbose=2,save_weights_only=True,monitor='val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We define the optimizer and compile the model. Notice we use a custom loss here ```MultiboxLoss```. We will take a look at this loss in depth later, but for now let's move on until we have our model training. Since it will take a while, it will give us some time to review technical details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from ssd_training import MultiboxLoss\n",
    "\n",
    "base_lr = 1e-3\n",
    "optim = Adam(lr=base_lr)\n",
    "model.compile(optimizer=optim,\n",
    "              loss=MultiboxLoss(NUM_CLASSES, neg_pos_ratio=2.0).compute_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We start training the model here. We will only do 2 epochs to be able to see some intermediate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 2\n",
    "# 1 epoch - 500s running on titanX or K80 GPU (batch size 64)\n",
    "history = model.fit_generator(gen.generate(True), gen.train_batches,\n",
    "                              nb_epoch, verbose=2,\n",
    "                              callbacks=[mc],\n",
    "                              validation_data=gen.generate(False),\n",
    "                              nb_val_samples=gen.val_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once it finishes the 2 epochs, run it again for longer. We will see the performance of the model in the next lab session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### While we are waiting...\n",
    "\n",
    "#### 1. Loss function\n",
    "As a reminder, the loss used to train this model is defined with the following equations. First, we have that the loss is a combination of the detection loss ($L_{loc}$) and classification loss ($L_{conf}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"../figs/total_loss.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's see the two loss components:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"../figs/loc_loss.PNG\" style=\"width: 600px;\"/>\n",
    "\n",
    "<img src=\"../figs/smoothl1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$L_{loc}$ is defined as the smooth L1 distance between parameterized box coordinates. Notice that $L_{loc}$ is only computed for positive classes. Boxes that are labeled as background do not contribute to the loss at all.  $g$ and $l$ are the ground truth and predicted bounding box coordinates. See how box coordinates are regressed to offsets wrt anchor boxes $d$ in the equations above. $x$ gives the matching pairs between ground truth and predicted boxes, which is obtained by selecting the pairs with an IoU over a certain threshold. You can check the implementation of $L_{loc}$ in ```ssd_training.py```.\n",
    "\n",
    "$L_{conf}$ is the multiclass softmax loss. Check the implementation in ```ssd_training.py```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"../figs/class_loss.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, let's check the implementation of total loss computation in ```ssd_training.py``` to see how these two are combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2. Model architecture\n",
    "\n",
    "In the paper, the authors give the following figure for the model architecture:\n",
    "\n",
    "<img src=\"../figs/ssd_arch.PNG\">\n",
    "\n",
    "Now let's look at ```ssd.py``` to see how this is implemented in keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once training has finished, we can take a look at some of the predictions that the model is able to make for some of our images. First we define a function to display boxes above a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "voc_classes = ['Aeroplane', 'Bicycle', 'Bird', 'Boat', 'Bottle',\n",
    "               'Bus', 'Car', 'Cat', 'Chair', 'Cow', 'Diningtable',\n",
    "               'Dog', 'Horse','Motorbike', 'Person', 'Pottedplant',\n",
    "               'Sheep', 'Sofa', 'Train', 'Tvmonitor']\n",
    "\n",
    "def display_boxes(img,preds,th):\n",
    "    # Parse the outputs.\n",
    "    det_label = preds[:, 0]\n",
    "    det_conf = preds[:, 1]\n",
    "    det_xmin = preds[:, 2]\n",
    "    det_ymin = preds[:, 3]\n",
    "    det_xmax = preds[:, 4]\n",
    "    det_ymax = preds[:, 5]\n",
    "\n",
    "    # Get detections with confidence higher than 0.6.\n",
    "    top_indices = [i for i, conf in enumerate(det_conf) if conf >= score_thresh]\n",
    "\n",
    "    top_conf = det_conf[top_indices]\n",
    "    top_label_indices = det_label[top_indices].tolist()\n",
    "    top_xmin = det_xmin[top_indices]\n",
    "    top_ymin = det_ymin[top_indices]\n",
    "    top_xmax = det_xmax[top_indices]\n",
    "    top_ymax = det_ymax[top_indices]\n",
    "\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "\n",
    "    plt.imshow(img / 255.)\n",
    "    plt.axis('off')\n",
    "    currentAxis = plt.gca()\n",
    "\n",
    "    for i in range(top_conf.shape[0]):\n",
    "        xmin = int(round(top_xmin[i] * img.shape[1]))\n",
    "        ymin = int(round(top_ymin[i] * img.shape[0]))\n",
    "        xmax = int(round(top_xmax[i] * img.shape[1]))\n",
    "        ymax = int(round(top_ymax[i] * img.shape[0]))\n",
    "        score = top_conf[i]\n",
    "        label = int(top_label_indices[i])\n",
    "        label_name = voc_classes[label - 1]\n",
    "        display_txt = '{:0.2f}, {}'.format(score, label_name)\n",
    "        coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "        color = colors[label]\n",
    "        currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n",
    "        currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5})\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's take a few validation images and test how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "\n",
    "inputs = []\n",
    "images = []\n",
    "\n",
    "idxs = [0,2,10,15]\n",
    "for idx in idxs:\n",
    "    img_path = path_prefix + sorted(val_keys)[idx]\n",
    "    img = image.load_img(img_path, target_size=(300, 300))\n",
    "    img = image.img_to_array(img)\n",
    "    images.append(imread(img_path))\n",
    "    inputs.append(img.copy())\n",
    "inputs = preprocess_input(np.array(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(inputs, batch_size=1, verbose=0)\n",
    "results = bbox_util.detection_out(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "score_thresh = 0.7\n",
    "for i, img in enumerate(images):\n",
    "    display_boxes(img,results[i],score_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Results don't look very good at the moment, but we should probably train for a lot longer ! In the next lab session we will use a pretrained model and test it on some images."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
